\chapter{Algebraic Effects}\label{chap:algebraic_effects}

The theory of algebraic effects is intended to make working with effectful operations easier by making effects composable. It achieves this goal for many important effects, but, crucially, does not cover higher-order effects; effect operations that take other effectful computations as arguments. The theory of hefty algebras extend extends the theory of algebraic effects with higher-order effects. How this is achieved is discussed in \cref{chap:higher_order}.

Elaine is based on the theory of hefty algebras, which is an extension of the theory of algebraic effects. Hence, the theory of algebraic effects also applies to Elaine. In this chapter, we give an introduction to algebraic effects. In the next chapter, we discuss its limitations regarding higher-order effects and describe how hefty algebras overcome those limitations.

\section{Monads}

\TODO{Some more background and citations on monads}
We will build up the notion of algebraic effects from monads. Monads are an abstraction over effectful computation commonly used in functional programming.

While many descriptions of monads using category theory and various analogies can be employed in explaining them, for our purposes, a monad is a type constructor \hs{m} with two associated functions: \hs{return} and \hs{>>=}, with the latter pronounced ``bind''. In Haskell, this concept is easily encoded in a type class, which is listed below.

\begin{lst}{Haskell}
class Monad m where
  return :: a -> m a
  (>>=) :: m a -> (a -> m b) -> m b
\end{lst}
%
This class tells us that we can construct a value of \hs{m a} for any type \hs{a} and for any monad \hs{m} using \hs{return}. This represents a computation that has no further effects and just ``returns'' a value. Additionally, we can compose two monadic computations using \hs{>>=}, which takes a monadic computation and a \emph{continuation}, which is the function that should be called after the operation has been performed. The continuation is passed the return value of the operation as an argument. The \hs{>>=} operator therefore sequences two monadic operations.

To explain how effectful operations can be encoded with this, we can look at a simple example: the \hs{Maybe} monad. Our goal with this monad is to create an ``abort'' effect, where the computation stops and returns immediately once \hs{Nothing} is encountered. To represent the intention of the operation, we define an \hs{abort} function which just returns \hs{Nothing}.

\begin{lst}{Haskell}
data Maybe a
  = Just a
  | Nothing

class Monad Maybe where
  return = Just
  
  Just a  >>= k = k a
  Nothing >>= k = Nothing

abort :: Maybe a
abort = Nothing
\end{lst}
%
With this definition, we can chain functions returning \hs{Maybe}. For example, we can define a \hs{head} function with the type \hs{[a] -> Maybe a} that returns the first element of a list if it is non-empty and \hs{Nothing} otherwise. We can also define a division function which checks that the divisor is non-zero. These functions can then be composed using \hs{>>=}.

\begin{lst}{Haskell}
head :: [a] -> Maybe a
head (x:xs) = Just x
head _ = Nothing

safeDiv :: Int -> Int -> Maybe Int
safeDiv _ 0 = Nothing
safeDiv x y = div x y

main = do
  print $ head []      >>= safeDiv 10 -- -> Nothing
  print $ head [0,1,2] >>= safeDiv 10 -- -> Nothing
  print $ head [2,3,4] >>= safeDiv 10 -- -> Just 5
\end{lst}
%
A more involved example is the \hs{State} monad. If we were to keep track of state manually a function that modifies state would need to take some state of type \hs{s} as an argument and return a new value for the state. Therefore, if a function \hs{foo} normally is a function with type \hs{a -> b}, it would need to have the type \hs{a -> s -> (s, b)}. Instead of modifying the state directly, it maps an old state to a new state. Then we need to ensure that we update the state with the modified value. For example, if the function is called multiple times, the code would look something like the code before.

\begin{lst}{Haskell}
-- Increment the state by `a` and return the old state
inc :: Int -> Int -> (Int, Int)
inc a s = (s + a, s)

multipleIncs :: Int -> (Int, Int)
multipleIncs s = let
  (s' , _) = inc 5 s
  (s'', _) = inc 6 s'
  in inc 7 s''
\end{lst}
%
The program becomes verbose and repetitive as a result. Looking at the signature \hs{a -> s -> (s, b)}, we can see that there is a possibility for abstraction here: we can abstract over the pattern of \hs{s -> (s, b)}. Our definition of the \hs{State} type constructor then becomes:

\begin{lst}{Haskell}
newtype State s a = State (s -> (s, a))

-- so that the inc function becomes:
inc :: Int -> State Int Int
inc a = State $ \s -> (s + a, s)
\end{lst}
%
That might look like a step backwards at first, but we can now implement the monad functions for \hs{State s} to allow us to compose functions returning the \hs{State} type. Additionally, we define the \hs{get} and \hs{put} operations, which are the basic building blocks we can use to build more complex operations.

\begin{lst}{Haskell}
instance Monad (State s) where
  return x = State $ \s -> (s, x)

  State fa >>= k = State $ \s ->
    let (s', a) = fa s
        State fb = k a
     in fb s'

get :: State s s
get = State $ \s -> (s, s)

put :: s -> State s ()
put = State $ \s -> (s, ())
\end{lst}
%
For convenience, we also define \hs{runState} to allow us to provide an initial state and evaluate the entire computation.

\begin{lst}{Haskell}
runState :: s -> State s a -> (s, a)
runState initialState (State s) = s initialState
\end{lst}
%
The \hs{inc} operations can then be sequenced using the \hs{>>=} operator. Because the return value of \hs{inc} is irrelevant in the computation, we define a shorthand operator \hs{>>}, which ignores the return value of the first operation.

\begin{lst}{Haskell}
(>>) :: Monad m => m a -> m b -> m b
ma >> mb = ma >>= \_ -> mb

inc :: Int -> State Int Int
inc x = get >>= \s -> put (s + x) >>= return s

multipleIncs :: State Int Int
multipleIncs = inc 5 >> inc 6 >> inc 7

main = print $ runState 0 bar # prints 0 + 5 + 6 + 7 = 18
\end{lst}
%
This is the power of monads: they allow us to abstract the effectful operations away, while also signalling the effects that a function requires in the return type. In the final example, we do not have to think about how the \hs{State} monad works anymore, but only use the \hs{get} and \hs{put} operations to build complex computations. With this abstraction, there is a separation between the interface and the implementation of the state effect. This modularity is one of the core motivation of any theory of effects. 

To make working with monads more convenient, Haskell also features do-notation, which is syntactic sugar for the \hs{>>=} and \hs{>>} operators. Using do-notation, the \hs{multipleIncs} computation from the previous example can be written as

\begin{lst}{Haskell}
multipleIncs = do
  inc 5
  inc 6
  inc 7
\end{lst}
%
If the results from the \hs{inc} computations needs to be used, the \hs{<-} operator, which is part of the do-notation, can be used to bind the result of a computation to a variable. For example, the sum of all the results from the \hs{inc} calls can be returned.

\begin{lst}{Haskell}
multipleIncs = do
  a <- inc 5
  b <- inc 6
  c <- inc 7
  return (a + b + c)

-- which is equivalent to
multipleIncs = 
  inc 5 >>= \a ->
    inc 6 >>= \b ->
      inc 7 >>= \c ->
        return (a + b + c)
\end{lst}
%
This is a convenient method for programming with effects in Haskell, while also staying true to its functional paradigm. However, monads are also limited, since they cannot be composed. Imagine, for instance, a computation that decrements some state and returns the new value, but also asserts that the value never becomes negative and returns \hs{Nothing} in that case. This computation might looks as follows.

\begin{lst}{Haskell}
decrement :: State Int (Maybe Int)
decrement = get >>= \s ->
              if s > 0
              then put (s - 1) >>= get >>= pure . pure
              else pure abort
\end{lst}
%
What's important here is that \hs{Maybe} cannot benefit from the \hs{>>=} operator. The type of \hs{decrement} is not a combined monad for both effects, but one monad wrapped in another. If we would then want to change the type to \hs{Maybe (State Int Int)}, the entire computation would need to be rewritten.

\begin{lst}{Haskell}
decrement :: Maybe (State Int Int)
decrement = (pure get) >>= \s ->
              if s > 0
              then pure (put (s - 1) >>= get)
              else abort
\end{lst}
%
For complex computations, this quickly gets complicated. Instead, there could be some combined monad \hs{MaybeAndState} that combines the operations of both monads.

\begin{lst}{Haskell}
decrement :: MaybeAndState Int Int
decrement = get >>= \s ->
              if s > 0
              then put (s - 1) >>= get
              else abort
\end{lst}
%
While it is technically possible to define such a monad, we would need to define one for every combination of monad operations that we would like to use, which quickly becomes very cumbersome. Hence, we need to look elsewhere for a solution. One solution to this is to use monad transformers, as explained in \cref{sec:monad_transformers}. Another solution is to use the \emph{free monad}.

\section{Effect Composition with the Free Monad}

\TODO{Cite Casper's blog or a more academic version of it from somewhere. http://casperbp.net/posts/2023-07-algebraic-effects/index.html}

\TODO{Give this description another go}
The free monad is a monad that encodes the structure of a program without imposing semantics \citationneeded. The free monad takes a functor \hs{f} as an argument. The free monad then gives a syntactic description of the operations given by that functor. It is therefore the trivial monad parametrized by the operations of \hs{f}. In Haskell, the free monad is implemented as the \hs{Free} data type.

\begin{lst}{Haskell}
data Free f a
  = Pure a
  | Do (f (Free f a))

instance Functor f => Monad (Free f) where
  return = Pure
  Pure x >>= f = f x
  Do g >>= f = Do $ fmap (>>= f) g
\end{lst}
%
Given some \hs{State s} functor, then \hs{Free (State s)} is a monad. Of course, this is only useful if the \hs{State s} functor can generate a monad with the same functionality as the original state monad. To do so, we define a data type with the two constructors of \hs{State}. This is a functor over the \hs{k} parameter, which represents the \emph{continuation} of the computation, which is the rest of the computation to be evaluated after the effect operation. Note that we do not have to give definitions of \hs{return} and \hs{>>=} since those are defined generically for any \hs{f} on \hs{Free}. We only have to derive the default \hs{Functor} instance.

\begin{lst}{Haskell}
data State s k = Put s k | Get (s -> k)
  deriving Functor
\end{lst}
%
Similarly, we can apply the free monad to \hs{Maybe}. However, the \hs{Just} constructor of the \hs{Maybe} is already covered by the \hs{Pure} constructor of the free monad, so \hs{Maybe} can be simplified to a single constructor. We call this simplified type \hs{Abort}. The \hs{Abort} constructor does not use the continuation because it signals that evaluation should stop.

\begin{lst}{Haskell}
data Abort k = Abort
  deriving Functor
\end{lst}
%
In contrast with monads, these functors can be meaningfully composed. We define a type-level operator \hs{+}, which represents a coproduct for functors. This operator can be thought of as \hs{Either} for functors, since \hs{Either} is the coproduct for types. We use this operator to build lists of functors. Just like lists have a \hs{Cons} and \hs{Nil}, these lists consist of \hs{+} and \hs{End}, where \hs{End} is a functor without any constructors.

\begin{lst}{Haskell}
infixr 6 +
data (f + g) a = L (f a) | R (g a)
  deriving Functor

data End k
  deriving Functor
\end{lst}
%
The \hs{End} functor has the property that it does not add any operations. Therefore, we have that
\code{Free (f + End)} is functionally the same as \code{Free f} and that \code{Free End a} is equivalent to \hs{a}. We can then make monads for any combination of the functors we have defined, such as \hs{Free (State s + End)}, \hs{Free (Abort + End)} or \hs{Free (State s + Abort + End)}. In general, we can construct a monad for any set of functors.

However, we have no way to use any of the effect operations for this functor. For example, if we have \hs{Free (State s + Abort + End)}, how would we use the \hs{get} operation that we expect from the state monad? The solution is to give a definition for \hs{get} for the free monad if and only if \hs{State} is one of the composed functors. We do this with a typeclass relation \hs{<}, which defines an injection from a functor \hs{f} to any composed functor \hs{g} that contains \hs{f}. We can use this injection to define \hs{get}, \hs{put} and \hs{abort}. These convenience functions are called \emph{smart constructors}.

\TODO{Parts of this might not be important}
\begin{lst}{Haskell}
class f < g where
  inj :: f k -> g k

instance f < f where inj = id
instance f < (f + g) where inj = L
instance f < h => f < (g + h) where inj = R . inj

get :: State s < f => Free f s
get = Do $ inj $ Get Pure

put  :: State s < f => s -> Free f ()
put s = Do $ inj $ Put $ Pure ()

abort :: Abort < f => Free f ()
abort = Do $ inj $ Abort
\end{lst}
%
This makes it possible to construct a computation using all those operations. For example, a computation that checks the state, asserts that it is larger than 0 and then decrements the state by 1.

\begin{lst}{Haskell}
decrement :: Free (State Int + Abort + End) Int
decrement = get >>= \s ->
              if s > 0
              then put (s - 1) >>= pure (s - 1)
              else abort 
\end{lst}
%
However, there is no way to evaluate this computation, because the free monad is just a syntactic representation of the computation. To do that, there needs to be a function with the type
\[\mcode{Free (f + f') a -> Free f' b}\]
for every \hs{f} and finally a \hs{Free End a -> a} to reduce the free monad to a final value. Following \textcite{castagna_handlers_2009}, these functions are called \emph{handlers}. Using a fold over the free monad, the definition of the handlers can be reduced to two smaller functions:
\begin{itemize}
    \item the return case, \hs{a -> Free f' b};
    \item and the case for handling the operations: \hs{f (Free f' b) -> Free f' b}.
\end{itemize}
However, to generalize the handler, we add a parameter \hs{p} as well, which is a parameter that the handlers can access. This paremeter is used to thread state through the computation. Therefore, \hs{handle} is defined as follows.

\begin{lst}{Haskell}
fold :: Functor f => (a -> b) -> (f b -> b) -> Free f a -> b
fold gen _   (Pure x) = gen x
fold gen alg (Op f)   = alg (fmap (fold gen alg) f)

handle :: (Functor f, Functor f')
       => (a -> p -> Free f' b)
       -> (f (p -> Free f' b) -> p -> Free f' b)
       -> Free (f + f') a -> p -> Free f' b
handle ret f = fold ret $
  \case
    L x -> f x
    R x -> \p -> Do $ fmap (\m -> m p) x
\end{lst}
%
Handlers for the various effects can then be constructed using \hs{handle}. For each computation, we need a handler for each effect and finally we reduce the free monad with only the \hs{End} functor to the final value. So, \hs{decrement} requires handlers for state and abort.

\begin{lst}{Haskell}
-- The Do case does not need to be handled since End cannot be
-- constructed
handleEnd :: Free End a -> a
handleEnd (Pure a) = a

handleAbort :: Functor f => Free (Abort + f) a -> Free f (Maybe a)
handleAbort c = handle
  (\a _ -> Pure $ Just a)
  (\Abort () -> Pure Nothing) 
  c ()
  
handleState :: Functor f => s -> Free (State s + f) a -> Free f (s, a)
handleState = flip $ handle
  (\x s -> pure (s, x))
  (\x s -> case x of
      Put s' k -> k s'
      Get k -> k s s)

result :: (Int, Maybe Int)
result = handleEnd $ handleState (0::Int) $ handleAbort decrement  
\end{lst}
%
This finally allows us to use the abort and state effects together, while providing a handler per effect. Note that the order in which the handlers are applied matters for the return type of the result. If abort is handled first and state second, the final type is \hs{(Int, Maybe Int)}. If state is handled first, is \hs{Maybe (Int, Int)}.

While the plumbing needed for a free monad is extensive, it is worth considering what it provides. First, we can combine multiple functors in our type signatures. Second, we can define operations that work for any effect composition that contains an effect. Third, we can provide modular handlers that handle a single effect from the composed functors. If all effects are defined in this way, then effect is automatically compatible with all other effects.

Finally, we have not only gained modularity for the effects themselves, but also for the handlers. The effects have become a specification of the syntax, while the handlers provide the semantics. Within this framework, the type and definition of the computation then does not need to be changed, only the handler. There is nothing preventing different implementations of the handlers. It is, for example, possible to define a state handler in which \hs{put} operations are ignored, keeping the state is constant.

\section{Algebraic Effects}

The free monad encoding in the previous section is an implementation of algebraic effects in Haskell. The term ``algebraic'' comes from the fact that this method works for effects that can be described as algebraic theories \autocite{goos_adequacy_2001}. Later, \textcite{plotkin_algebraic_2003} showed that this is only possible for effects that satisfy the \emph{algebraicity property}.

The algebraicity property states that the \hs{>>=} operation distributes over the computation parameters of an operation. This means that if there is some operation \hs{op} that has some parameter of type \hs{k} then the following computations should be equivalent:
\[ \mcode{(op k) >>= k'}\quad==\quad\mcode{op (k >>= k')} \] 
By construction, this holds for any effect we have defined in the previous section. This can be derived from the definitions of \hs{>>=} on \hs{Free} and \hs{fmap} for the effects. For example, we can apply the definitions to \hs{Free (State s)}.

\begin{lst}{Haskell}
-- we start with:
put s >>= k
-- expand smart constructor:
Do (Put s (Pure ())) >>= k
-- apply >>= of Free:
Do $ fmap (>>= k) (Put s (Pure ()))
-- apply fmap of Put:
Do $ Put s (Pure () >>= k)
-- simplify
Do $ Put s k
\end{lst}
%
The state and abort effects satisfy this property, along with effects for non-determinism, cooperative concurrency\todo{and more}. However, \emph{higher-order effects} such as exception catching and the reader effect with a local operation are not algebraic. Those effects are discussed extensively in \cref{chap:higher_order}.

\section{Building a Language with Algebraic Effects}

Although the previous sections contain an encoding of algebraic effects, there are details in this encoding that we might like to hide. For instance, writing all return types as \hs{Free f a} for every function becomes repetitive. Every returned value also needs to be wrapped in \hs{pure} to be mapped to the monad. Our goal is then to remove as much of the additional syntax that is required to work with effects when compared to pure functions.

This is where we reach the limits of what we can achieve with the encoding of the free monad in Haskell. If we instead design a new language which integrates algebraic effects as a core feature in the language, we have much more freedom in designing a syntax and type system that work well for thus purpose.

Elaine is a language with support for algebraic effects, but it also supports higher-order effects. Therefore, this section focuses on Koka \autocite{leijen_koka_2014,leijen_koka_2023}, which only supports algebraic effects. Since Elaine is heavily inspired by Koka, the same concepts apply to Elaine.

At the core of such languages lies the following concept: all functions implicitly return the free monad with some effects. Therefore, we write \code{a -> e b}, which is analogous to \code{a -> Free e b} in the Haskell encoding. In that signature, we call \code{e} the \emph{effect row} and its elements as \emph{effects}. So, the function signature \hs{a -> e b} should be read as: this function takes an \hs{a} and returns \hs{b} with effect row \hs{e}.

Instead of using type-level operators, we can introduce special syntax for effect rows, too. Following Koka, we will write effect rows as
\begin{center}\texttt{<e1,e2,...,eN>}.\end{center}
In the type system, we are then allowed to use different orders of effects interchangeably. This is a clear ergonomic improvement over the free monad encoding, where we could only reason about inclusion of one effect at a time. 

In such a language, effects are a special construct separate from monads and functors. Therefore, effect rows can get special treatment in the type system. It should be able to, for example, reason about equality between effect rows with the same effects in different orders, such as \el{<a,b>} and \el{<b,a>}.

All the effects in this row are single effects, they are not composed. In Haskell, this is not the case, some functor \hs{f} can represent a composed functor. Therefore we need notation to express that an effect row can be extended with another effect row. This is written as
\begin{center}\texttt{<e1,e2,...,eN|es>,}\end{center}
where \el{es} is the tail of the effect row; a variable representing the effect row with which this effect row can be extended.

We can define the same effects as before, like state and abort, but in Koka, we do not define them as functors. Instead, we define them using the \code{effect} keyword and each constructor of the functors is then declared with the \code{ctl} keyword.

\begin{lst}{Koka}
effect abort
  ctl abort(): a

effect state<a>
  ctl get(): a
  ctl put(x: a): ()
\end{lst}
\feedback{Deze alineas verdienen wat liefde en aandacht.}
The equivalent of \hs{Free (State s + Abort + End) a} becomes \el{<state<s>,abort> a}. The equivalent of a handler would then be a function which takes \el{() -> <f|e> a} and returns \el{<|e> a}. In Koka, such a function can be defined with the \el{handler} construct, which requires an implementation for each operation of an effect and a special function for the return case. Note the similarity to the \hs{handle} function we defined in Haskell before. In the case of abort effect, this handler is assigned to variable for later use. The state handler is wrapped in another function which takes an initial value for the state.

\begin{lst}{Koka}
val hAbort = handler
  return(x)   Just(x)
  ctl abort() Nothing

fun hState(init, c)
  fun h(c')
    with handler
      return(x)  fn(s) (s, x)
      ctl get()  fn(s) resume(s)(s)
      ctl put(n) fn(_) resume(())(n)
    c'()
  
  h(c)(init)
\end{lst}
\TODO{Note that Koka is more ``inspired'' by free monads, because the arbitrary return types are hard to do in Haskell.}
This saves us from specifying some details, but the structure is largely the same as with the free monad encoding. The larger differences become apparent when we want to use the effects. A port of the decrement function is listed below.


\begin{lst}{Koka}
fun decrement(): <state<int>,abort> int
  val s = get()
  if s == 0 then
    abort()
  
  put(s - 1)
  s - 1 

fun printMaybe(m: maybe<int>)
  match m
    Just(x) -> println(x)
    Nothing -> println("nothing!")

fun main()
  printMaybe(hAbort { hState(3, foo) } ) // prints "2"
  printMaybe(hAbort { hState(0, foo) } ) // prints "nothing!"
\end{lst}
%
The \hs{>>=} operator is entirely implicit here. Therefore, it is similar to Haskell's do-notation. However, in do-notation, every effectful operation needs to be on a separate line. For example, if the state needs to be incremented by 1, this can be achieved in one line in Koka, but in Haskell using do-notation requires two lines.

\begin{lst}{Koka}
put(get() + 1)
\end{lst}
\begin{lst}{Haskell}
do
  x <- get
  put (x + 1)
\end{lst}
%
In Koka, effectful operations can be used anywhere as long as they are wrapped in a corresponding handler. In the end, the syntax is closer to imperative programming languages than functional programming languages.

However, the type system still very much resembles that of a functional language. This is important because this means that we have not lost any of the type safety that the monadic treatment of effects provides. The signature of a function in Koka still gives a complete specification of all effects that a function might perform. In imperative languages, this information is entirely missing from the function signature. For example, the type system can to assert that a function is entirely pure. In the listing below, the \hs{<>} in the type of the function asserts that it does not require effects, yet the \hs{println} function requires an effect. Hence, Koka's type checker will yield a type error.

\begin{lst}{Koka}
fun should_be_pure(x: int): <> int
  println("This will give a type error!")
  x + 10
\end{lst}
%
As will become clear in \cref{chap:basics}, Elaine takes a lot of inspiration from Koka. Handlers and effects are defined in the same way, modulo some syntactical difference. What sets Elaine apart, is that it also supports higher-order effects, which will be explained in the next chapter.
